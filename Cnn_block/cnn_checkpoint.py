# -*- coding: utf-8 -*-
"""CNN-checkpoint.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pgekyE1thvlnnavHTbW_Hpfj0ArhtLUr
"""

import numpy as np 
np.random.seed(1337) 
import pandas as pd 

import os
import glob
import pandas as pd
import soundfile as sf
import scipy.signal as signal
import matplotlib.pyplot as plt
import gc
import librosa

gc.collect()

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()

def padding(signal,max_length=80001):
  remaining = max_length-len(signal)
  return np.pad(signal, (remaining//2, remaining-remaining//2), 'constant', constant_values=(0, 0))

#extraida de https://github.com/tomasz-oponowicz/spoken_language_identification
def generate_fb_and_mfcc(signal, sample_rate):

    # Pre-Emphasis
    pre_emphasis = 0.97
    emphasized_signal = np.append(
        signal[0],
        signal[1:] - pre_emphasis * signal[:-1])

    # Framing
    frame_size = 0.025
    frame_stride = 0.01

    # Convert from seconds to samples
    frame_length, frame_step = (
        frame_size * sample_rate,
        frame_stride * sample_rate)
    signal_length = len(emphasized_signal)
    frame_length = int(round(frame_length))
    frame_step = int(round(frame_step))

    # Make sure that we have at least 1 frame
    num_frames = int(
        np.ceil(float(np.abs(signal_length - frame_length)) / frame_step))

    pad_signal_length = num_frames * frame_step + frame_length
    z = np.zeros((pad_signal_length - signal_length))

    # Pad Signal to make sure that all frames have equal
    # number of samples without truncating any samples
    # from the original signal
    pad_signal = np.append(emphasized_signal, z)

    indices = (
        np.tile(np.arange(0, frame_length), (num_frames, 1)) +
        np.tile(
            np.arange(0, num_frames * frame_step, frame_step),
            (frame_length, 1)
        ).T
    )
    frames = pad_signal[indices.astype(np.int32, copy=False)]

    # Window
    frames *= np.hamming(frame_length)

    # Fourier-Transform and Power Spectrum
    NFFT = 512

    # Magnitude of the FFT
    mag_frames = np.absolute(np.fft.rfft(frames, NFFT))

    # Power Spectrum
    pow_frames = ((1.0 / NFFT) * ((mag_frames) ** 2))

    # Filter Banks
    nfilt = 40

    low_freq_mel = 0

    # Convert Hz to Mel
    high_freq_mel = (2595 * np.log10(1 + (sample_rate / 2) / 700))

    # Equally spaced in Mel scale
    mel_points = np.linspace(low_freq_mel, high_freq_mel, nfilt + 2)

    # Convert Mel to Hz
    hz_points = (700 * (10**(mel_points / 2595) - 1))
    bin = np.floor((NFFT + 1) * hz_points / sample_rate)

    fbank = np.zeros((nfilt, int(np.floor(NFFT / 2 + 1))))
    for m in range(1, nfilt + 1):
        f_m_minus = int(bin[m - 1])   # left
        f_m = int(bin[m])             # center
        f_m_plus = int(bin[m + 1])    # right

        for k in range(f_m_minus, f_m):
            fbank[m - 1, k] = (k - bin[m - 1]) / (bin[m] - bin[m - 1])
        for k in range(f_m, f_m_plus):
            fbank[m - 1, k] = (bin[m + 1] - k) / (bin[m + 1] - bin[m])
    filter_banks = np.dot(pow_frames, fbank.T)

    # Numerical Stability
    filter_banks = np.where(
        filter_banks == 0,
        np.finfo(float).eps,
        filter_banks)

    # dB
    filter_banks = 20 * np.log10(filter_banks)

    # MFCCs
    # num_ceps = 12
    # cep_lifter = 22

    # ### Keep 2-13
    # mfcc = dct(
    #     filter_banks,
    #     type=2,
    #     axis=1,
    #     norm='ortho'
    # )[:, 1 : (num_ceps + 1)]

    # (nframes, ncoeff) = mfcc.shape
    # n = np.arange(ncoeff)
    # lift = 1 + (cep_lifter / 2) * np.sin(np.pi * n / cep_lifter)
    # mfcc *= lift
    #filter_banks -= (np.mean(filter_banks, axis=0) + 1e-8)
    return filter_banks

X_train,y_train,X_test,y_test = [],[],[],[]
LANGUAGE = {'asm':0,'ben':1,'guj':2,'hin':3,
            'kan':4,'mal':5,'odi':6,'tel':7}
folders = glob.glob('Data_LID/train/')
for folder in folders:
    for lang in ['asm','ben','guj','hin','kan','mal','odi','tel']:
        cnt =  0
        for f in glob.glob(folder+'/'+lang+'/*.wav'):
            x,sr = librosa.load(f,sr=None)
            x = padding(x)
            MFCC = generate_fb_and_mfcc(x,sr)
            MFCC_sc = sc.fit_transform(MFCC)
            X_train.append(MFCC_sc)
            y_train.append(LANGUAGE[lang])
            cnt+=1
            #if cnt==1000:break

data = list(zip(X_train,y_train))
np.random.shuffle(data)
X_train,y_train = zip(*data)
del data
print(f'# of train set: {len(X_train)}')

folders = glob.glob('Data_LID/test/')
for folder in folders:
    for lang in ['asm','ben','guj','hin','kan','mal','odi','tel']:
        cnt =  0
        for f in glob.glob(folder+'/'+lang+'/*.wav'):
            x,sr = librosa.load(f,sr=None)
            x = padding(x)
            MFCC = generate_fb_and_mfcc(x,sr)
            MFCC_sc = sc.fit_transform(MFCC)
            X_test.append(MFCC_sc)
            y_test.append(LANGUAGE[lang])
            cnt+=1
            #if cnt==1000:break
            
print(f'# of test set: {len(X_test)}')

data = list(zip(X_test,y_test))
np.random.shuffle(data)
X_test,y_test = zip(*data)
del data

X_train = np.array(X_train)
X_test = np.array(X_test)

from sklearn import preprocessing
from sklearn.metrics import classification_report,confusion_matrix

import tensorflow
from tensorflow.keras.models import Model, load_model, Sequential
from tensorflow.keras.layers import (
    BatchNormalization, SeparableConv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense, Input, Conv2D
)
from tensorflow.keras.optimizers import Nadam, SGD, Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from keras.utils import np_utils
from tensorflow.keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint
from keras import regularizers
from keras import backend as K

input_shape = (998,40,1)
model = Sequential()

model.add(Conv2D(32,(7, 7), activation='relu', padding='valid', input_shape=input_shape))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(3,3), strides=2, padding='same'))
model.add(Conv2D(64,(5,5), activation='relu', padding='same'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(3,3), strides=2, padding='same'))
model.add(Conv2D(128,(3,3), activation='relu', padding='same'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(3,3), strides=2, padding='same'))
model.add(Conv2D(256,(3,3), activation='relu', padding='same'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(3,3), strides=2, padding='same'))
model.add(Conv2D(512,(3,3), activation='relu', padding='same'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(3,3), strides=2, padding='same'))
model.add(Flatten())
model.add(BatchNormalization())
model.add(Dense(256, activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(0.35))
model.add(Dense(8, activation='softmax'))


#sgd = SGD(lr=0.01, decay=1, momentum=0.0, nesterov=False)
#sgd = sgd(lr=0.01, decay=1e-6, momentum=0.0, nesterov=False)
#adam = Adam(lr=0.01, decay=1e-6)
import math
from keras.callbacks import LearningRateScheduler
adam = Adam(learning_rate=0.0001, decay=1e-6)
def step_decay(epoch):
    # 00158 = 90.4%
	initial_lrate = 0.00158
	drop = 0.9
	epochs_drop = 1
	lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))
	return lrate


model.compile(loss='categorical_crossentropy',optimizer=adam,metrics=['accuracy'])



checkpoint = ModelCheckpoint(
                'model.h5',
                monitor='val_accuracy',
                verbose=0,
                save_best_only=True,
                mode='max'
                )

lrate = LearningRateScheduler(step_decay)
#es = EarlyStopping(monitor='val_loss',mode = 'max')
model.fit(
                X_train,
                pd.get_dummies(y_train),
                epochs=10,
                callbacks=[checkpoint],
                verbose=1,
                validation_data=(X_test,
                pd.get_dummies(y_test),),
                batch_size=64)

model = load_model('model.h5')
model.fit(
                X_train,
                pd.get_dummies(y_train),
                epochs=10,
                callbacks=[checkpoint],
                verbose=1,
                validation_data=(X_test,
                pd.get_dummies(y_test),),
                batch_size=128)

model = load_model('CNN_Akashwani.h5')

y_pred = model.predict(X_test)
y_pred = y_pred.argmax(axis=1)

confusion_matrix(y_test,y_pred)

print(classification_report(y_test,y_pred))

y_pred = model.predict(X_train)
y_pred = y_pred.argmax(axis=1)

confusion_matrix(y_train,y_pred)

print(classification_report(y_train,y_pred))

model.save('CNN_Akashwani.h5')

X_test,y_test = [],[]
LANGUAGE = {'asm':0,'ben':1,'guj':2,'hin':3,
            'kan':4,'mal':5,'odi':6,'tel':7}

folders = glob.glob('IITMandi_YouTube/')
for folder in folders:
    for lang in ['asm','ben','guj','hin','kan','mal','odi','tel']:
        cnt =  0
        for f in glob.glob(folder+'/'+lang+'/*.wav'):
            x,sr = librosa.load(f,sr=None)
            x = x[:80001]
            x = padding(x)
            MFCC = generate_fb_and_mfcc(x,sr)
            MFCC_sc = sc.fit_transform(MFCC)
            X_test.append(MFCC_sc)
            y_test.append(LANGUAGE[lang])
            cnt+=1
            #if cnt==1000:break
            
print(f'# of test set: {len(X_test)}')

data = list(zip(X_test,y_test))
np.random.shuffle(data)
X_test,y_test = zip(*data)
del data

X_test = np.array(X_test)

y_pred = model.predict(X_test)
y_pred = y_pred.argmax(axis=1)

confusion_matrix(y_test,y_pred)

print(classification_report(y_test,y_pred))

