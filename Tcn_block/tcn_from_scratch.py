# -*- coding: utf-8 -*-
"""TCN from Scratch-checkpoint.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CFqG_gicgLwnPBIcG3Q1DnffzAqmPbLn
"""

from keras.layers import (Input, Conv1D, Conv2D, SeparableConv2D, Dense, Activation, MaxPooling1D, MaxPooling2D,
                          GlobalMaxPooling1D,Flatten, Dropout, BatchNormalization, Reshape)
from keras.models import Model, Sequential, load_model
import tensorflow
from tensorflow.keras.optimizers import Nadam, SGD, Adam
from tensorflow.keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint

from sklearn import preprocessing
from sklearn.metrics import classification_report,confusion_matrix

import numpy as np 
np.random.seed(1337) 
import pandas as pd 

import os
import glob
import pandas as pd
import soundfile as sf
import scipy.signal as signal
import matplotlib.pyplot as plt
import gc
import librosa

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()

#extraida de https://github.com/tomasz-oponowicz/spoken_language_identification
def generate_fb_and_mfcc(signal, sample_rate):

    # Pre-Emphasis
    pre_emphasis = 0.97
    emphasized_signal = np.append(
        signal[0],
        signal[1:] - pre_emphasis * signal[:-1])

    # Framing
    frame_size = 0.025
    frame_stride = 0.01

    # Convert from seconds to samples
    frame_length, frame_step = (
        frame_size * sample_rate,
        frame_stride * sample_rate)
    signal_length = len(emphasized_signal)
    frame_length = int(round(frame_length))
    frame_step = int(round(frame_step))

    # Make sure that we have at least 1 frame
    num_frames = int(
        np.ceil(float(np.abs(signal_length - frame_length)) / frame_step))

    pad_signal_length = num_frames * frame_step + frame_length
    z = np.zeros((pad_signal_length - signal_length))

    # Pad Signal to make sure that all frames have equal
    # number of samples without truncating any samples
    # from the original signal
    pad_signal = np.append(emphasized_signal, z)

    indices = (
        np.tile(np.arange(0, frame_length), (num_frames, 1)) +
        np.tile(
            np.arange(0, num_frames * frame_step, frame_step),
            (frame_length, 1)
        ).T
    )
    frames = pad_signal[indices.astype(np.int32, copy=False)]

    # Window
    frames *= np.hamming(frame_length)

    # Fourier-Transform and Power Spectrum
    NFFT = 512

    # Magnitude of the FFT
    mag_frames = np.absolute(np.fft.rfft(frames, NFFT))

    # Power Spectrum
    pow_frames = ((1.0 / NFFT) * ((mag_frames) ** 2))

    # Filter Banks
    nfilt = 40

    low_freq_mel = 0

    # Convert Hz to Mel
    high_freq_mel = (2595 * np.log10(1 + (sample_rate / 2) / 700))

    # Equally spaced in Mel scale
    mel_points = np.linspace(low_freq_mel, high_freq_mel, nfilt + 2)

    # Convert Mel to Hz
    hz_points = (700 * (10**(mel_points / 2595) - 1))
    bin = np.floor((NFFT + 1) * hz_points / sample_rate)

    fbank = np.zeros((nfilt, int(np.floor(NFFT / 2 + 1))))
    for m in range(1, nfilt + 1):
        f_m_minus = int(bin[m - 1])   # left
        f_m = int(bin[m])             # center
        f_m_plus = int(bin[m + 1])    # right

        for k in range(f_m_minus, f_m):
            fbank[m - 1, k] = (k - bin[m - 1]) / (bin[m] - bin[m - 1])
        for k in range(f_m, f_m_plus):
            fbank[m - 1, k] = (bin[m + 1] - k) / (bin[m + 1] - bin[m])
    filter_banks = np.dot(pow_frames, fbank.T)

    # Numerical Stability
    filter_banks = np.where(
        filter_banks == 0,
        np.finfo(float).eps,
        filter_banks)

    # dB
    filter_banks = 20 * np.log10(filter_banks)

    # MFCCs
    # num_ceps = 12
    # cep_lifter = 22

    # ### Keep 2-13
    # mfcc = dct(
    #     filter_banks,
    #     type=2,
    #     axis=1,
    #     norm='ortho'
    # )[:, 1 : (num_ceps + 1)]

    # (nframes, ncoeff) = mfcc.shape
    # n = np.arange(ncoeff)
    # lift = 1 + (cep_lifter / 2) * np.sin(np.pi * n / cep_lifter)
    # mfcc *= lift
    #filter_banks -= (np.mean(filter_banks, axis=0) + 1e-8)
    return filter_banks

from BUT import audio2bottleneck
def BNF(f):
    bnf = audio2bottleneck.compute("BabelMulti",f)
    return bnf

def wav2bnf(f):
    bnf = BNF(f)
    outputfile = (f.replace('Data','BNF')).replace('wav','csv')
    np.savetxt(outputfile, bnf, delimiter=",") #save BNF as .csv

LANGUAGE = {'asm':0,'ben':1,'eng':2,
            'guj':3,'hin':4,'kan':5,
            'mal':6,'mar':7,'odi':8,
            'pun':9,'raj':10,'tam':11,
            'tel':12}

for dataset in ['PB','YT']:
    for dataset_ in ['train','test']:
        folders = glob.glob('Data/'+dataset+'/'+dataset_+'/')
        for folder in folders:
            for lang in LANGUAGE.keys():
                cnt =  0
                for f in glob.glob(folder+'/'+lang+'/*.wav'):
                    wav2bnf(f)

X_train,y_train,X_test,y_test = [],[],[],[]
LANGUAGE = {'asm':0,'ben':1,'eng':2,
            'guj':3,'hin':4,'kan':5,
            'mal':6,'mar':7,'odi':8,
            'pun':9,'raj':10,'tam':11,
            'tel':12}

folders = glob.glob('BNF/PB/train/')
for folder in folders:
    for lang in LANGUAGE.keys():
        cnt =  0
        for f in glob.glob(folder+'/'+lang+'/*.csv'):
            X_train.append(f)
            y_train.append(LANGUAGE[lang])
            cnt+=1
            #if cnt==10:break
            
data = list(zip(X_train,y_train))
np.random.shuffle(data)
X_train,y_train = zip(*data)
del data
print(f'# of train set: {len(X_train)}')

folders = glob.glob('BNF/PB/test/')
for folder in folders:
    for lang in LANGUAGE.keys():
        cnt =  0
        for f in glob.glob(folder+'/'+lang+'/*.csv'):
            X_test.append(f)
            y_test.append(LANGUAGE[lang])
            cnt+=1
            #if cnt==10:break
            
print(f'# of test set: {len(X_test)}')

data = list(zip(X_test,y_test))
np.random.shuffle(data)
X_test,y_test = zip(*data)
del data

batch_size, timesteps, input_dim = None, None, 80
def OHE(y):
    y_ohe = np.zeros(13)
    y_ohe[y] = 1
    return y_ohe.reshape(1,-1)

def train_generator():
    index = 0
    while True:
      f = X_train[index]
      Bnf = np.loadtxt(f,delimiter=',')
      #Bnf_sc = sc.fit_transform(Bnf)
      x = Bnf.reshape(1,-1,input_dim)
      y = OHE(y_train[index])
        
      yield x,y
      index+=1
      index%=len(X_train)


def val_generator():
    index = 0
    while True:
      f = X_test[index]
      Bnf = np.loadtxt(f,delimiter=',')
      #Bnf_sc = sc.fit_transform(Bnf)
      x = Bnf.reshape(1,-1,input_dim)
      y = OHE(y_test[index])
        
      yield x,y
      index+=1
      index%=len(X_test)

model = Sequential()
model.add(Input(batch_shape=(batch_size, timesteps, input_dim)))
model.add(Conv1D(filters=128, kernel_size=2, activation='relu',padding = 'causal', dilation_rate = 1))
model.add(Dropout(0.15))
model.add(Conv1D(filters=128, kernel_size=2, activation='relu', padding = 'causal', dilation_rate = 2))
model.add(Dropout(0.15))
model.add(Conv1D(filters=128, kernel_size=2, activation='relu' ,padding = 'causal', dilation_rate = 4))
model.add(Dropout(0.15))
model.add(Conv1D(filters=128, kernel_size=2, activation='relu', padding = 'causal', dilation_rate = 8))
model.add(Dropout(0.15))
model.add(Conv1D(filters=128, kernel_size=2, activation='relu' ,padding = 'causal', dilation_rate = 16))
model.add(Dropout(0.15))
model.add(Conv1D(filters=128, kernel_size=2, activation='relu', padding = 'causal', dilation_rate = 32))
model.add(GlobalMaxPooling1D())
# Flatten the output of the convolutional layers
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.20))
model.add(Dense(13, activation='softmax'))
print(model.summary())

adam = Adam()#learning_rate=1e-3, decay=1e-6)
# Compile model with Adam optimizer and binary cross-entropy loss
model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])

checkpoint = ModelCheckpoint(
                'TCN_scratch_PB_BNF.h5',
                monitor='val_accuracy',
                verbose=1,
                save_best_only=True,
                mode='max'
                )

model.fit(
                train_generator(),
                steps_per_epoch=len(X_train),
                epochs=30,
                callbacks=[checkpoint],
                verbose=1,
                validation_data=val_generator(),validation_steps=len(X_test))

model = load_model(filepath='TCN_scratch_PB_BNF.h5')
model.summary()

adam = Adam(learning_rate=1e-5, decay=1e-2)
model = load_model(filepath='TCN_scratch_PB_BNF.h5')
model.compile(loss='categorical_crossentropy',optimizer=adam,metrics=['accuracy'])
checkpoint = ModelCheckpoint(
                'TCN_scratch_PB_BNF.h5',
                monitor='val_accuracy',
                verbose=1,
                save_best_only=True,
                mode='max'
                )
model.fit(
                train_generator(),steps_per_epoch=len(X_train),
                epochs=20,
                callbacks=[checkpoint],
                verbose=1,
                validation_data=val_generator(),validation_steps=len(X_test))

model.save('TCN_scratch_PB_BNF.h5')